\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2021

% ready for submission
\usepackage[preprint]{neurips_2021}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2021}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2021}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2021}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{float}
\title{Talent Scouting in League of Legends \\ using LCK Challenger League Data}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Stefan Fauth\\
  Matrikelnummer 5706097\\
  \texttt{stefan.fauth@student.uni-tuebingen.de}
} 
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\


\begin{document}

\maketitle

\titlespacing\section{0pt}{11pt plus 0pt minus 4pt}{0pt plus 0pt minus 4pt}
\titlespacing\subsection{0pt}{11pt plus 0pt minus 4pt}{0pt plus 0pt minus 4pt}


\begin{abstract}
After giving a basic introduction to the video game League of Legends, this article outlines weaknesses of commonly used player performance metrics and suggests alternatives that overcome these. The validity of the suggested metrics is, then, proven by using data from a major secondary professional league: five out of the ten best players, defined by the metrics, secured a spot in a major primary league, the year after. 
\end{abstract}

\section{Introduction}

League of Legends (LoL) is a popular Multiplayer Online Battle Arena (MOBA), created by Riot Games, which is played by more than 100 Million people, per month, around the globe \citep{kollar2016past}. In the main game mode, each player gets to choose one of 158 characters (champions) of whom each has different abilities and thus, strengths and weaknesses at different points of the game. Each team has, at each time point, a fixed amount of resources (gold and experience) available. Experience allows for unlocking new abilities or upgrading already unlocked abilities, while gold allows for itemization that improves in and out of combat statistics. Players then fight over non-neutral and neutral objectives to be the first to destroy the enemy nexus, which, immediately, ends the game. One game consists of two teams, where each team consists of five players, of which each one has a different role. \newline Due to the highly competitive nature of the game \citep{kou2016ranking}, players look up to the best players that participate in professional leagues. The Korean professional league (LCK), as well as the Korean, public, server are widely regarded as being the highest-competitive environment for players.  Consequently, except for the interest of Korean teams in finding domestic talent, non-Korean teams have, however due to cultural and language barriers with varying success, imported Korean players into their rosters. In order to prevent teams from an excessive practice of importing and to support local talents, Riot Games has imposed limitations on importing. Even though this rule still holds, non-Korean teams remain interested in talent from the Korean server. \newline The present study seeks to suggest criteria that can be utilized to measure the latent skill level of a player. As in other sports, this level is driven by a row of variables: psychological, sociological factors, maturation, chance, an athlete's environment, game intelligence and tactical understanding \citep{williams2020talent}. The main difference to regular sports lies in the fact that physical features of an athlete are replaced by cognitive and fine-motor ability (mechanics). Due to the lack of data, researchers are forced to measure the joint, combined statement of these factors, i.e the skill level, by analyzing in-game outcomes. Nevertheless, due to the small amount of research done in this field, generally accepted key performance indicators (KPI) have several issues. This article gives a short overview of these KPIs, whose theoretical foundation oversimplifies the nature of the game by, outlining their weaknesses and suggests advantageous alternatives.


\section{Main Hypotheses}
\subsection{Team bias and opportunity cost question the validity of common metrics}
First, the reader will be provided with a small breakdown of problematic KPIs: 
in general, to assess the validity of an indicator, it has to be shown that it is robust against the influence of the team (team bias).
As a consequence of a potential team bias, raw, absolute indicators, such as a player's winrate, CS/m (Creep Score per minute) or average KDA ($\frac{kills + assists}{deaths}$) cannot be considered useful: like in soccer, having strong teammates automatically lets you win games, even if you perform poorly. Added to that, having the top scorer on your team, also increases the likelihood of scoring assists or last-hitting goals, i.e. kills. It also grants you more access to neutral resources, distorting the CS/m. Furthermore, outcomes such as KDA and CS/m also greatly depend on matchups and general team compositions. In order to prioritize other position's matchups, the coach might draft a losing top lane champion, which could result in a low KDA and CS/m score for the top laner, which can not be attributed to a player's capabilities. \newline
Except for the aforementioned team bias, average CS/m, as well as average gold per minute (GP/m) are also problematic in terms of opportunity cost. The nature of the limited availability of resources suggests that if one player has a huge amount of resources (XP and gold), the others can not have as much. Yet, having a lot of resources does not exclusively mean that a players helps in winning the game.  This is a matter of efficiency: certain players manage to have a, comparetively, big impact in the game with less resources required, indicating these players can be considered superior. Moreover, the general notion of opportunity cost suggests that committing time to accumulate resources means that a player can not do other things at the same time: in particular, with regard to claiming neutral objectives, sometimes, a team might benefit more from a player grouping with the rest of the team or securing vision than having the player collecting resources. 


\subsection{Alternatives}
After illustrating several pitfalls of popular metrics, now, criteria will be presented that are designed to address these problems. Subsequently, the reader will be provided with explanations, outlining reasons, why they are able to address them. \newline The first two metrics DPM per gold ($DPM^*$) and Net KP per gold ($KP^*$) cover gold efficiency:
\begin{equation}
DPM^* = \frac{dmg \%}{gold \%} \quad\mathrm{and}\quad 
KP^* =  \frac{KA \% - D \%}{gold \%} \indent \indent ,
\end{equation}
in which $dmg\%$ is the average share of team's total damage to champions in $\%$, 
$gold\%$ the average share of team's total gold in $\%$, 
$KA\%$ the average share of team's kills in $\%$, where a player earned a kill or an assist and
$D\%$ the average share of team's total deaths in $\%$.
\newline 
The idea behind these metrics is that we want to model a player's gold efficiency by his damage per percentage of team gold and by his number of clean (net) kill participations. By using fractions of team's stats, the team bias gets removed, at least to some extent. Even if the team is losing, a well performing player will still have a high fractions of the team's damage and net kills. Assuming a general consensus across all teams about the currently strongest champions, role assignments and playstyles (meta), all players can be expected to play, on average more or less, the same champions, eliminating a bias in the data, caused by a high fraction of unfavorable matchups of a player.  \newline
The aforementioned metrics account for the team bias by expressing a player's performance by expressing his performance as a fraction of the whole team's. Another strategy to cope with the team bias could be to, simply, consider metrics that do not depend, as much, on the team, i.e. metrics that describe the isolated comparison of a player and his counterpart in the enemy team. In the early game (the first 10 minutes of the game), this is mostly the case. Early ganks and skirmishes tend to happen. Let's assume that independently of the team, these events have the same probability to happen, which means that we can disregard them. Added to that, beside the first dragon, no neutral objectives, except for jungle camps, are available. Therefore, it can be concluded that accumulating resources can not be associated with high opportunity cost. It suffices to look at the gold and the xp difference, as the cs is just one cause of these differences. Furthermore, the gold and xp difference also incorporate early kills and assists. Yet, in pro play, they could be greatly influenced by which player actually gets to pick his champ later than his opponent. Thus, let's normalize the average gold and xp differences by the fraction of games, where a player had a chance to pick his champion after his opponent, indicating a potential counterpick. This yields Net Gold difference ($GD^*$) and Net XP difference pre minute 10 ($XPD^*$):
\begin{equation}
GD^*  =  \frac{gdif}{counter \%} 
\quad\mathrm{and}\quad
XPD^* =  \frac{xpdif}{counter \%} ,
\end{equation}

in which $gdif$ is the average gold difference at minute 10,
$xpdif\%$ the average difference in experience at minute 10 $\%$ and
$counter\%$ the fraction of games in which a player picked after his direct opponent.


\section{Methods: Data collection and aggregation}


The data source,
\href{https://oracleselixir.com/stats/players/byTournament}{Oracle's Elixir}, provided for each  stage of the competitive year 2021 of the LCK Challenger League (both regular splits and playoffs) one table, including all players participating in the respective stage. For each player, general information, such as team, position, number of games played, and winrate was available. Added to that, the data included specific KPIs summarizing a player's average, total game performance, e.g. KDA. Some metrics also captured a player's average outcomes until minute 10. To assess the quality of the metrics, the professional status of players that were identified as outstandingly talented, was retrieved from a \href{https://lol.fandom.com/wiki/League_of_Legends_Esports_Wiki}{fan-made LoL wiki.}  \newline
As the main objective of the analysis was to identify players, who consistently perform better than their role-specific competitors, the data for average outcomes in one stage was averaged over all stages, a player took part in. Lastly, players who played less than twenty games were removed from the dataset, as their KPIs are not credible, due to low sample size.
\section{Results}
%Assuming a Beta prior, Bayesian inference on %team's winrates have shown that the winrate's %posterior distributions overlap greatly, %indicating that creating groups of relatively %better and worse teams can be discarded. 
\setlength{\intextsep}{0.00005cm}

The first plot provides a role-wise comparison of the metrics DPM per gold and Net KP per gold, while the second one illustrates Net Gold difference and Net XP difference pre minute 10 for each player. In order to obtain a measure for the joint statement of all KPIs, the average metric rank of each player, within his position, was computed. Based on this ranking, the top two players, per position, were identified and marked with a star. Athletes that play in a primary league in the first competitive stage of the year 2022 are marked with a six-pointed star (five out of the ten best). To express the certainty in the estimate, the size of each marker was designed to positively correlate with the number games a player has played. If the reader prefers a table instead of figures, Table 1 summarizes the main statements of the plots.
\begin{figure}[H]
\includegraphics[scale=0.33]{newplot2.png}

\end{figure}
%\vspace{-2pt}
\begin{figure}[H]
\includegraphics[scale=0.33]{newplot.png}

\end{figure}



\begin{table}[h]
\begin{threeparttable}
\caption{Outstanding players based on their role-specific average metric rank}
\begin{tabular}{lllrrr}
\toprule
    Player &                  Team & Position &  Games &  Winrate in \% &  Average metric rank \\
\midrule
     Chasy &              DWG KIA  &      Top &     27 &         30.50 &                 1.75 \\
      Mask &  Hanwha Life Esports  &   Middle &     50 &         51.66 &                 2.50 \\
      Kael &                Gen.G  &  Support &     51 &         63.25 &                 2.50 \\
      DnDn &    Nongshim RedForce  &      Top &     48 &         50.34 &                 3.25 \\
 Berserker &                   T1  &      ADC &     42 &         70.31 &                 3.50 \\
    HyBriD &           KT Rolster  &      ADC &     24 &         48.50 &                 3.50 \\
     Seize &         Liiv SANDBOX  &   Jungle &     46 &         40.50 &                 3.50 \\
  YoungJae &                Gen.G  &   Jungle &     35 &         60.34 &                 3.50 \\
     Rebel &           KT Rolster  &  Support &     30 &         23.50 &                 3.75 \\
     Keine &     Kwangdong Freecs  &   Middle &     28 &         41.66 &                 4.25 \\
\bottomrule
\end{tabular}
%\begin{tablenotes}
%\item \textbf{Notes:} \\ \textit{LC: Linear %Combination \\ OB: Offensive Behavior \\
%DB: Defensive Behavior \\
%CBS: Close Ball Situation}
%\end{tablenotes}
\end{threeparttable}

\end{table}
\newpage
The plots show a clear separation of the players within their role. Except for athletes from KT Rolster and Gen.G, the best players were on different teams. Also, a more or less symmetric distribution of their winrates can be observed. Both observations point at a potential elimination of the team bias, assuming all players in the league are, on average, equally skillful. Among all roles, no player does strictly dominate all other players. Yet, on average, DWG KIA's top-laner Chasy seems to have, consistently, outperformed other players. 
\section{Limitations}
The analyst should question the validity of these indicators, simply due to the difference in sample size. Certain players have played more games than other players, indicating higher certainty in their estimates as a true measure of their skill.  \newline Added to that, one can also question the applicability of all metrics to every role. Particularly for the bot lane, being a lane that is played by two players, early differences in XP and gold can be greatly biased by a lane partner's behavior. In order to overcome this, one should, perhaps rather, look at the joint resource difference of a botlane, than at individual differences. \newline Besides, for a complete, objective evaluation of the validity of the metrics, the future status of all players would be necessary, instead of just the top ten players.

\section{Conclusion}
Beside their theoretical validity, applying the data to actual data, also, showed that the suggested metrics are able to reduce the team bias. They can help identifying outstanding players in the ocean of already highly-talented, pre-selected players. Yet, stakeholders should not, blindly, trust these metrics, as they are, just, indicators of a player's true skill level, which remains latent.







%Schlechte KP, da scaling pick (liegt nicht am %Spieler).Aber im durchschnitt ist meta für alle %gleich, was ähnliche picjks für alle teams %suggeriert




\bibliography{citations_2}



\end{document}
